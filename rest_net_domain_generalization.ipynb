{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-04-20 18:44:20.895258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-04-20 18:44:20.895325: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import torch\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","import matplotlib.image as mpimg\n","import numpy as np\n","from PIL import Image\n","from torchvision import transforms\n","import os\n","import tensorflow as tf\n","from keras.layers.core import Dense ,Flatten\n","# from tensorflow.keras import layers,Dense,Flatten\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["dataset={}\n","dataset[\"PACS\"] = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n","x=dataset[\"PACS\"]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class_dict={\n","    \"dog\":0,\n","    \"elephant\":1,\n","    \"giraffe\":2,\n","    \"guitar\":3,\n","    \"horse\":4,\n","    \"house\":5,\n","    \"person\":6\n","}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["opt = {\n","    'image_size': 32,\n","    'is_grayscale': False,\n","    'val_split': 0.75\n","}\n","def load_image(path):\n","    # im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')\n","    # im = im.resize((opt['image_size'],opt['image_size']))\n","    # im = np.array(im)\n","    # im = im/256\n","    # return im\n","    img = mpimg.imread(path)\n","    return img\n","def display_images(imgs,classes,row=1,col=2,w=3,h=3):\n","    fig=plt.figure(figsize=(2, 2))\n","    for i in range(1, col*row +1):\n","        img = imgs[i-1]\n","        fig.add_subplot(row, col, i)\n","        \n","        if opt['is_grayscale']:\n","            plt.imshow(img , cmap='gray') \n","        else:\n","            plt.imshow(img)\n","    plt.show()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def load_data(dir_path,class_name):\n","    image_list = []\n","    y_list = []\n","    filenames=[]\n","    label_dict = class_dict\n","    for filename in sorted(os.listdir(dir_path)):\n","        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n","            im = load_image(os.path.join(dir_path,filename))\n","            # y = filename.split('_')[0]\n","            y = label_dict[class_name] \n","            image_list.append(im)\n","            filenames.append(os.path.join(dir_path,filename))\n","            y_list.append(y)\n","        else:\n","            continue\n","    return image_list,y_list,filenames"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class_labels=[\"dog\",\"elephant\",\"giraffe\",\"guitar\",\"horse\",\"house\",\"person\"]\n","data_types=[\"art_painting\",\"cartoon\",\"photo\",'sketch']"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["path=\"../pacs_data/\""]},{"cell_type":"markdown","metadata":{},"source":["complete_data=[]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["art_train=[]\n","art_val=[]\n","art_test=[]\n","cartoon_train=[]\n","cartoon_val=[]\n","cartoon_test=[]\n","photo_train=[]\n","photo_val=[]\n","photo_test=[]\n","# cartoon_train=[]\n","# cartoon_val=[]\n","# cartoon_test=[]\n","# complete_art=[]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# def get_data():\n","for data_type in data_types:\n","  complete_data=[]\n","  y_labels=[]\n","  # print(data_type)\n","  for class_label in class_labels:\n","    new_path=path+\"/\"+data_type+\"/\"+class_label+\"/\"\n","    X,y,filenames = load_data(new_path,class_label)\n","    # complete_data.append(X)\n","    #display_images(X,0)\n","    # len=len(X)\n","    for i in X:\n","      complete_data.append(i)\n","    for j in y:\n","      y_labels.append(j)\n","  if data_type==\"art_painting\":\n","    complete_art=complete_data\n","    complete_art_labels=y_labels\n","  if data_type==\"cartoon\":\n","    complete_cartoon=complete_data\n","    complete_cartoon_labels=y_labels\n","  if data_type==\"photo\":\n","    complete_photo=complete_data\n","    complete_photo_labels=y_labels\n","  if data_type==\"sketch\":\n","    complete_sketch=complete_data\n","    complete_sketch_labels=y_labels"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["2048"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(complete_art)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["2048"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["len(complete_art_labels)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# complete_data = np.array(complete_data)\n","complete_art = np.array(complete_art)\n","# complete_photo = np.array(complete_photo)\n","# complete_sketch = np.array(complete_sketch)\n","# complete_cartoon= np.array(complete_cartoon)\n","# complete_art_labels = np.array(complete_art_labels)\n","# complete_photo_labels = np.array(complete_photo_labels)\n","# complete_sketch_labels = np.array(complete_sketch_labels)\n","# complete_cartoon_labels= np.array(complete_cartoon_labels)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["complete_art_labels = np.array(complete_art_labels)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 0, 0, ..., 6, 6, 6])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["complete_art_labels"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["encoded = to_categorical(complete_art_labels)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["encoded"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# print(complete_cartoon.shape)\n","# print(complete_art.shape)\n","# print(complete_photo.shape)\n","# print(complete_sketch.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["complete_art_features =[]\n","complete_photo_features = []\n","complete_sketch_features =[]\n","complete_cartoon_features= []\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from torchvision import *\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/aman/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:21<00:00, 2.16MB/s]\n"]}],"source":["net = models.resnet18(pretrained=True)\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# net = net.cuda() if device else net\n","\n","# net"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'use_cuda' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m num_ftrs \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[1;32m     15\u001b[0m net\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m net\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mif\u001b[39;00m \u001b[43muse_cuda\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m net\u001b[38;5;241m.\u001b[39mfc\n","\u001b[0;31mNameError\u001b[0m: name 'use_cuda' is not defined"]}],"source":["criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n","\n","\n","def accuracy(out, labels):\n","\n","    _,pred = torch.max(out, dim=1)\n","\n","    return torch.sum(pred==labels).item()\n","\n","\n","num_ftrs = net.fc.in_features\n","\n","net.fc = nn.Linear(num_ftrs, 128)\n","\n","# net.fc = net.fc.cuda() if use_cuda else net.fc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-04-20 17:31:41.145253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n","2022-04-20 17:31:41.155415: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-04-20 17:31:41.162161: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (diksha-Lenovo-ideapad-330-15IKB): /proc/driver/nvidia/version does not exist\n","2022-04-20 17:31:41.404374: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"ename":"AttributeError","evalue":"module 'keras.api._v2.keras.applications' has no attribute 'ResNet18'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_9609/1325475737.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m pretrained_model= tf.keras.applications.ResNet18(include_top=False,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.applications' has no attribute 'ResNet18'"]}],"source":["resnet_model = Sequential()\n","\n","pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n","                   input_shape=(227,227,3),\n","                   pooling='avg',classes=7,\n","                   weights='imagenet')\n","for layer in pretrained_model.layers:\n","        layer.trainable=False\n","\n","resnet_model.add(pretrained_model)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["resnet_model.add(Flatten())\n","resnet_model.add(Dense(512, activation='relu'))\n","resnet_model.add(Dense(7, activation='softmax'))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 2048)              23587712  \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1049088   \n","                                                                 \n"," dense_1 (Dense)             (None, 7)                 3591      \n","                                                                 \n","=================================================================\n","Total params: 24,640,391\n","Trainable params: 1,052,679\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["resnet_model.summary()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/diksha/.local/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["resnet_model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["tf.config.run_functions_eagerly(True)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/diksha/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]}],"source":["history = resnet_model.fit(complete_art,encoded,batch_size=100, epochs=2)\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /home/diksha/.cache/torch/hub/pytorch_vision_v0.10.0\n"]}],"source":["    model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n","    ### strip the last layer\n","    # feature_extractor = torch.nn.Sequential(*list(model_ft.children())[:-1])\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["for image in complete_art:\n","        input_image = Image.open(image)\n","        input_tensor = preprocess(input_image)\n","        input_batch = input_tensor.unsqueeze(0)\n","        with torch.no_grad():\n","            output = model_ft(input_batch)\n","        break\n","    \n","            "]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 1000])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["output.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["    # for image in complete_art:\n","    #     input_image = Image.open(image)\n","    #     input_tensor = preprocess(input_image)\n","    #     input_batch = input_tensor.unsqueeze(0)\n","    #     with torch.no_grad():\n","    #         output = feature_extractor(input_batch)\n","    #         output =output.reshape(512)\n","    #     complete_art_features.append(output)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["    # for image in complete_photo:\n","    #     input_image = Image.open(image)\n","    #     input_tensor = preprocess(input_image)\n","    #     input_batch = input_tensor.unsqueeze(0)\n","    #     with torch.no_grad():\n","    #         output = feature_extractor(input_batch)\n","    #         output =output.reshape(512)\n","\n","    #     complete_photo_features.append(output)\n","\n","    # meta_train_features = np.array(complete_art_features+complete_photo_features)\n","    # complete_art_features= np.array(complete_art_features)\n","    # complete_photo_features= np.array(complete_photo_features)\n","\n","    # for image in complete_sketch:\n","    #     input_image = Image.open(image)\n","    #     input_tensor = preprocess(input_image)\n","    #     input_batch = input_tensor.unsqueeze(0)\n","    #     with torch.no_grad():\n","    #         output = feature_extractor(input_batch)\n","    #         output =output.reshape(512)\n","    #     complete_sketch_features.append(output)\n","\n","    # complete_sketch_features= np.array(complete_sketch_features)\n","\n","    # for image in complete_cartoon:\n","    #     input_image = Image.open(image)\n","    #     input_tensor = preprocess(input_image)\n","    #     input_batch = input_tensor.unsqueeze(0)\n","    #     with torch.no_grad():\n","    #         output = feature_extractor(input_batch)\n","    #         output =output.reshape(512)\n","    #         # output = feature_extractor(input_batch) # output now has the features corresponding to input x\n","    #     complete_cartoon_features.append(output)\n","\n","    # complete_cartoon_features= np.array(complete_cartoon_features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["    # meta_train_features\n","    # meta_train_labels = np.array(complete_art_labels+complete_photo_labels)\n","\n","    # complete_cartoon_features      #meta test features\n","    # complete_cartoon_labels        #meta test labels\n","\n","    # complete_sketch_features       #test features\n","    # complete_sketch_labels         #test labels\n","\n","    # return meta_train_features,meta_train_labels,complete_cartoon_features,complete_cartoon_labels,complete_sketch_features,complete_sketch_labels\n","    return complete_art_features"]},{"cell_type":"markdown","metadata":{},"source":["meta_train_features,meta_train_labels,complete_cartoon_features,complete_cartoon_labels,complete_sketch_features,complete_sketch_labels = get_data()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["complete_art_features = get_data()\n","print(len(complete_art_features))"]}],"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":2}
